{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7xTc4pxLN2jD"
   },
   "source": [
    "# Introduction to OpenCV\n",
    "## Computer Vision and Image Processing - Lab Session 2\n",
    "### Prof: Luigi Di Stefano, luigi.distefano@unibo.it\n",
    "### Tutor: Pierluigi Zama Ramirez, pierluigi.zama@unibo.it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. OpenCV\n",
    "\n",
    "OpenCV (Open source computer vision) is a library of programming functions mainly aimed at real-time computer vision.\n",
    "\n",
    "The library has more than 2500 optimized algorithms, which includes a comprehensive set of both classic and state-of-the-art computer vision and machine learning algorithms. These algorithms can be used to detect and recognize faces, identify objects, classify human actions in videos, track camera movements, track moving objects, extract 3D models of objects, produce 3D point clouds from stereo cameras, stitch images together to produce a high resolution image of an entire scene, find similar images from an image database, remove red eyes from images taken using flash, follow eye movements, recognize scenery and establish markers to overlay it with augmented reality, etc.\n",
    "\n",
    "To import the library in your python program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yzBOKWvGPYHV"
   },
   "source": [
    "To test if your import succeds, we can print each library version number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7qib-6HeOvrn"
   },
   "outputs": [],
   "source": [
    "print(\"The OpenCV version is:\", cv2.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this course we will use OpenCV 3.4.2.16 because it is the last version including free implementations of SIFT and SURF algorithms which we will use during this course. \n",
    "\n",
    "We need to import also **NumPy** and **Matplotlib** to work and display images in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Only for jupyter notebook visualization\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8lSls_wqQBRs"
   },
   "source": [
    "## 2. Load an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3KMH-xOeOwfO"
   },
   "source": [
    "First of all we learn to download media files to have some image data to work on. \n",
    "\n",
    "* Download \"avengers.png\" from https://iol.unibo.it. You should find it in the chapter *\"Laboratory slides and materials\"*.\n",
    "* Move it inside the folder of the notebooks (or change the path in the notebook accordingly).\n",
    "\n",
    "With the following snippet you will load the image:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Vz0LclFMtSi"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('avengers.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function **cv2.imread(*filename*)** load the image from the *filename* path. Although in this case we passed the **relative path** to the folder where you have the notebooks, you can pass also the **absolute path** to the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is an image under the hood in Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In C++, OpenCV employs its Mat matrix structure\n",
    "* But in **Python**, OpenCV represents images as **NumPy n-dimensional arrays**\n",
    "\n",
    "Since images are NumPy arrays, you are able to use all NumPy methods also on images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JhTWOhQKRsu4"
   },
   "source": [
    "For example we can print the shape of the image as we do with numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R6Py5e5QRnsi"
   },
   "outputs": [],
   "source": [
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UxakdPCBSUjI"
   },
   "source": [
    "The shape in case of images represents the **Height** and the **Width** of the image, along with the numbers of **channels**.\n",
    "\n",
    "In this case your image has an **Height = 549**, a **Width = 910** and **Channels = 3**. The shape *(H,W,C)* is a **Tuple**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O1rlSTHRSOzt"
   },
   "outputs": [],
   "source": [
    "# Printing height width and channels separately\n",
    "height = image.shape[0]\n",
    "width = image.shape[1]\n",
    "ch = image.shape[2]\n",
    "\n",
    "print(\"The Height is:\",height)\n",
    "print(\"The Width is: \",width)\n",
    "print(\"The Number of Channels is: \",ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, if you want to get the bit-depth (the number of bits per pixel) of an image you can print the dtype of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images have usually 8-bit depth, therefore, each pixel contains a value from 0 to 255 (i.e. uint8)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XnAqkecSVyws"
   },
   "source": [
    "## 3. Display the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K-3F5M0ZV1jO"
   },
   "source": [
    "Using Matplotlib we are able to display the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "liLSvGB_V0uy"
   },
   "outputs": [],
   "source": [
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OeXBR3y0XO3W"
   },
   "source": [
    "Why are the colors strange? \n",
    "\n",
    "Usually, colored images have 3 channels: **Red**, **Green** and **Blue** (**RGB**). Matplotlib requires images in this format to display them correctly. \n",
    "\n",
    "On the other hand, OpenCV loads images as **Blue**, **Green** and **Red** (**BGR**). \n",
    "\n",
    "It is just a convention. So if you want to  plot images with original colors using the library **matplotlib**, you need a conversion!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TSgeGQB5WHj3"
   },
   "outputs": [],
   "source": [
    "image_rgb = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wF-1XhViYxxI"
   },
   "source": [
    "And then, plot the new version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_pTUlinPYvLO"
   },
   "outputs": [],
   "source": [
    "plt.imshow(image_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W592P6k4ZeXo"
   },
   "source": [
    "The function **cv2.cvtColor(*image*,*converstion_type*)** will return the modified version of the original *image* applying the conversion represented by *converstion_type*. In this case the *converstion_type* is **cv2.COLOR_BGR2RGB** that means a converstion from BGR to RGB. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also set the figure dimension using **plt.figure(figsize=(height_value, width_value))**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10)) # (20,10) is the maximum allowed figure size.\n",
    "plt.imshow(image_rgb) # imshow changes the figure size to mantain the image's aspect ratio.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MP21kdTnawfe"
   },
   "source": [
    "## 4. Access Image Pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NQpQJepPa9k5"
   },
   "source": [
    "In Python a 2D image is represented as a Matrix. Each element of the matrix represents one **pixel**. Since a color image has 3 channels per pixel, our representation is not a simple Matrix, but is 3-dimensional array called **Tensor**.\n",
    "\n",
    "So let's try to access one random pixel. For example one belonging to the Ironman's suit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Jhpn4Mma6wX"
   },
   "outputs": [],
   "source": [
    "ironman_pixel = image[280,400]\n",
    "print(\"The pixel value is:\",ironman_pixel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HPAi1kMluMfE"
   },
   "source": [
    "With the previous notation we accessed to the pixel with *row=280*, *column=400*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!Only for visualization!!!\n",
    "\n",
    "# Drawing a white circle around the selected pixel\n",
    "# We first create a copy of the image to do the drawings without changing the original image\n",
    "image_copy = np.copy(image)\n",
    "cv2.circle(image_copy , (400,280), 20 ,[255, 255, 255], 5)\n",
    "plt.imshow(cv2.cvtColor(image_copy,cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n",
    "# !!!Only for visualization!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GK5OaG_ud8bq"
   },
   "source": [
    "A RGB image has 3 values per pixel representing the red, green and blue channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dZCFjw1bY1sW"
   },
   "outputs": [],
   "source": [
    "# Accessing blue, green and red values of the pixel\n",
    "\n",
    "blue = ironman_pixel[0]\n",
    "green = ironman_pixel[1]\n",
    "red = ironman_pixel[2]\n",
    "\n",
    "print(\"The BGR value of the pixel is: B={},G={},R={}\".format(blue,green,red))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qWaxplqtfCEx"
   },
   "source": [
    "As expected, the dominant color is **red** so the *red* value is higher than the *blue* and *green* values. What about an hulk pixel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rGjY-rQtc6WF"
   },
   "outputs": [],
   "source": [
    "# Pixel vector\n",
    "hulk_pixel = image[232,56]\n",
    "\n",
    "# Separated colors\n",
    "hulk_pixel_blue =  image[232,56,0]\n",
    "hulk_pixel_green = image[232,56,1]\n",
    "hulk_pixel_red =   image[232,56,2]\n",
    "\n",
    "print(\"The BGR value of the pixel is: B={},G={},R={}\".format(hulk_pixel_blue,hulk_pixel_green,hulk_pixel_red))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7X3sBKSxgOBj"
   },
   "source": [
    "In the previous example we have shown first of all that **Hulk is GREEN!** .. than we used another method to access image pixels. With two indices we access the image pixel:\n",
    "\n",
    "```\n",
    "pixel = image[232,56]\n",
    "```\n",
    "\n",
    "Hence, we address each pixel component with another index:\n",
    "\n",
    "\n",
    "```\n",
    "red = pixel[2]\n",
    "```\n",
    "\n",
    "Or we can retrieve the pixel component directly with 3 indices:\n",
    "\n",
    "\n",
    "```\n",
    "pixel_red = image[232,56,2]\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HpTR2pz_mPga"
   },
   "source": [
    "## 5. Grayscale Images vs Colored Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ltp2moYHm3hJ"
   },
   "source": [
    "In the previous sections we managed colored image only. But what about grayscale images? \n",
    "\n",
    "First of all download *\"lenna.png\"* from https://iol.unibo.it and move it to notebooks folder.\n",
    "\n",
    "To load a grayscale image we need to add **cv2.IMREAD_GRAYSCALE** in our **cv2.imread()** function otherwise OpenCV load a 3 channel colored image by default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_AAacTe6i3EV"
   },
   "outputs": [],
   "source": [
    "# Loading a Grayscale image\n",
    "grayscale_image = cv2.imread('lenna.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "print(\"The shape of this Grayscale Image is:\", grayscale_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kt6Psl64nbIo"
   },
   "source": [
    "**N.B.** Grayscale images have only **1 channel** so when loading them we will have no 3rd dimension in our array! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2yuK0s0wsrd8"
   },
   "source": [
    "Let's show the image (we add the 3 arguments *cmap='gray', vmin=0, vmax=255* to tell the plot library that is a grayscale picture with values from 0 to 255):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eCR3nY5Sl8rm"
   },
   "outputs": [],
   "source": [
    "plt.imshow(grayscale_image, cmap='gray', vmin=0, vmax=255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tzSkmo-5qZxw"
   },
   "source": [
    "So what about Pixels now? Each pixel now is not a vector anymore, but a single intensity value between 0-255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bqx90K6pl-Od"
   },
   "outputs": [],
   "source": [
    "print(grayscale_image[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iJB-8QXusAtG"
   },
   "source": [
    "**N.B** Remember that a pixel value of 0 is **Black** and a value of 255 is **White**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we want to convert color images into grayscale images. To do so we can use **cv2.cvtColor()** with a different flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_color2grayscale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "plt.imshow(image_color2grayscale, cmap='gray', vmin=0, vmax=255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Access R, G, B channels separately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W592P6k4ZeXo"
   },
   "source": [
    "In colored images each channel R,G,B can be seen as a single R,G,B image and you can plot it independetly. \n",
    "\n",
    "If we want to access the three channels separately we can do it easily using slicing (same as Numpy arrays!).\n",
    "\n",
    "In the following code we will extract the 3 channels representing the R,G,B values of the image and we will plot them in three different grayscale images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = image_rgb[:,:,0] # Getting the first axis, Red\n",
    "G = image_rgb[:,:,1] # Getting the second axis, Green\n",
    "B = image_rgb[:,:,2] # Getting the third axis, Blue\n",
    "\n",
    "# Each channel can be seen as a grayscale image\n",
    "print(R.shape, G.shape, B.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,3,1)\n",
    "plt.imshow(R, cmap='gray', vmin=0, vmax=255)\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(G, cmap='gray', vmin=0, vmax=255)\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(B ,cmap='gray', vmin=0, vmax=255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the image above you cannot disambiguate the three images because the 3 axis contain similar information. But let us try with a completely green image: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_image_bgr = cv2.imread(\"green.png\") # BGR by default\n",
    "green_image_rgb = cv2.cvtColor(green_image_bgr, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(green_image_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = green_image_rgb[:,:,0] # Getting the first axis, Red\n",
    "G = green_image_rgb[:,:,1] # Getting the second axis, Green\n",
    "B = green_image_rgb[:,:,2] # Getting the third axis, Blue\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(R, cmap='gray', vmin=0, vmax=255)\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(G, cmap='gray', vmin=0, vmax=255)\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(B ,cmap='gray', vmin=0, vmax=255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Only the Green channel has values greater than 0!**\n",
    "This is because only G channel has meaningful values different from 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**N.B.** Now that we know how to extract channels, we could perform the BGR to RGB conversion simply by splitting the channels and than concatenating them in the inverse order along the third dimension using **Numpy** methods. \n",
    "\n",
    "We can use **np.stack([R,G,B], axis=2)** to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking B,G,R along the axes of channels (axis=-1, last channel).\n",
    "\n",
    "B = image[:,:,0] # Getting the first axis, Red\n",
    "G = image[:,:,1] # Getting the second axis, Green\n",
    "R = image[:,:,2] # Getting the third axis, Blue\n",
    "\n",
    "image_rgb = np.stack([R,G,B], axis=-1) # Axis specifies the position of the new axis. -1 means last position. \n",
    "print('B, G and R shapes :',B.shape, G.shape, R.shape)\n",
    "print('image_rgb shape : ',image_rgb.shape)\n",
    "\n",
    "plt.imshow(image_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ATs-0E3EhYk5"
   },
   "source": [
    "## 7. Access Image Region of Interests (ROIs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TyhI6qB4hlLN"
   },
   "source": [
    "In the previous section we have seen how to access to single pixels. But what about a bigger portion of the image?\n",
    "We just need to do **slicing** as for all numpy arrays! \n",
    "For example in the following snippet we will cut **Captain America** out of the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6C-K9IqQfZAK"
   },
   "outputs": [],
   "source": [
    "captain_america = image_rgb[100:-1,400:820]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cB0xCxyltGZg"
   },
   "source": [
    "In the example above we accesed the RoI going from row 100 to last row (100:-1) and from column 400 to column 820 (400:820)\n",
    "\n",
    "**N.B.** The rows are ordered from top to bottom while the columns from left to right. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1vB2seREiZS_"
   },
   "source": [
    "Then show it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_6s0sWXgiJr1"
   },
   "outputs": [],
   "source": [
    "plt.imshow(captain_america)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hur2I0rbu_Q8"
   },
   "source": [
    "## 8. Modify pixels and Save image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eDBfzZy7vPeW"
   },
   "source": [
    "Up to now, we accessed pixels without modifying the original image.\n",
    "\n",
    "If we want to edit the value of a single pixel of the image we could do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Previous value: \", grayscale_image[0,0])\n",
    "grayscale_image[0,0] = 255\n",
    "print(\"New value: \",grayscale_image[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eDBfzZy7vPeW"
   },
   "source": [
    "Tipically, before to modify images, it is raccomended to make a backup of those images. To do so, we first **copy** the images and then we perform all modifications on the copy of the images.\n",
    "\n",
    "For example, let us try to edit the *lenna.png* grayscale image around a pupil of the girl:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZIfigX5Xpj-Q"
   },
   "outputs": [],
   "source": [
    "# Copy of the original image\n",
    "copied_image = grayscale_image.copy()\n",
    "\n",
    "# Pupil coordinates\n",
    "center_row = 264\n",
    "center_column = 268\n",
    "radius = 5\n",
    "\n",
    "new_color = 255 # White\n",
    "\n",
    "copied_image[center_row - radius : center_row + radius, center_column - radius: center_column + radius] = new_color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0BSxG2o9xNoE"
   },
   "source": [
    "Show the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8thgmNiAw-pu"
   },
   "outputs": [],
   "source": [
    "plt.imshow(copied_image, cmap='gray', vmin=0, vmax=255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice how the original image stayed unchanged:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(grayscale_image, cmap='gray', vmin=0, vmax=255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you have done the modifications, you can save the image on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"lenna_white_pupill.png\", copied_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of **color images** if we want to modify a pixel we have to assing 3 values, one for each channel BGR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copied_image_rgb = image_rgb.copy()\n",
    "\n",
    "print(\"Previous value: \", copied_image_rgb[0,0])\n",
    "copied_image_rgb[0,0] = [255,255,255]\n",
    "print(\"New value: \", copied_image_rgb[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try to mask captain america assigning all white pixels to the RoI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copied_image_rgb[100:-1,400:820] = np.asarray([255,255,255])\n",
    "plt.imshow(copied_image_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same way of before we can save the image. With **cv2.imwrite** we can save our image with several codings such as *.png, .jpg, .bmp, etc ...*. \n",
    "\n",
    "**N.B** As for loading image, OpenCV expects to have a BGR image by default, but we performed the masking operation on an RGB image. Remember to convert back to BGR before saving!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copied_image_bgr = cv2.cvtColor(copied_image_rgb, cv2.COLOR_RGB2BGR)\n",
    "cv2.imwrite(\"avengers_no_captain_america.jpg\", copied_image_bgr)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Computer Vision Lab 1.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
