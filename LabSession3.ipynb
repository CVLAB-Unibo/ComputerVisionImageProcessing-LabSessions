{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera Calibration\n",
    "## Computer Vision and Image Processing - Lab Session 3\n",
    "### Prof: Luigi Di Stefano, luigi.distefano@unibo.it\n",
    "### Tutor: Pierluigi Zama Ramirez, pierluigi.zama@unibo.it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Camera calibration is the process whereby all parameters defining the camera\n",
    "model are estimated for a specific camera device.\n",
    "\n",
    "The pinhole camera model is represented by the Perspective Projection Matrix\n",
    "(PPM), which in turn can be decomposed into 3 independent tokens: intrinsic\n",
    "parameter matrix (A), rotation matrix (R) and translation vector (T). Depending on\n",
    "the application, either the PPM only or also its independent components (A, R, T)\n",
    "need to be estimated.\n",
    "\n",
    "Many camera calibration algorithms do exist. The basic process, though, relies\n",
    "always on setting up a linear system of equations given a set of known 3D-2D\n",
    "correspondences, so as to then solve for the unknown camera parameters.\n",
    "\n",
    "To obtain the required correspondences specific physical objects (referred to as\n",
    "calibration targets) having easily detectable features (such as e.g. chessboard or\n",
    "dot patterns) are typically deployed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Camera calibration approaches can be split into two main categories:\n",
    "\n",
    "* Those relying on a single image featuring several (at least  2) planes containing a known pattern. \n",
    "* Those relying on several (at least 3) different images of one given planar pattern. \n",
    "\n",
    "In practise, it is difficult to build accurate targets containing multiple planes, while an accurate planar target can be attained rather easily. \n",
    "\n",
    "Implementing a camera calibration software requires a significant effort. However, the main Computer Vision toolbox include specific functions (OpenCV, Matlab CC Toolbox, Halcon.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing **Camera Calibration** with *OpenCV* and *Python*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we need to import the usual libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to define both the size of the square (measure it direcly using a ruler on the printed chessboard)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_size = 26.5 #mm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then define the number of inner corner per row and column. We will call it *pattern_size*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_size = (9,6) # number of inner corner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create a dictionary of the path to all the calibration images. (Take new ones if you want to calibrate your own camera or use the pictures contained inside *\"calibration/chessboards\"*).\n",
    "\n",
    "The **minimum** number of images to calibrate a camera is __3__. A rule of thumb is to take **at least 12** pictures because it is possible that you will not be able to detect the chessboard in all of them and it will make calibration results more robusts.\n",
    "\n",
    "Moreover, try to take both pictures with **several rotations of the chessboard**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['calibration/chessboards/0.jpg', 'calibration/chessboards/1.jpg', 'calibration/chessboards/2.jpg', 'calibration/chessboards/3.jpg', 'calibration/chessboards/4.jpg', 'calibration/chessboards/5.jpg', 'calibration/chessboards/6.jpg', 'calibration/chessboards/7.jpg', 'calibration/chessboards/8.jpg', 'calibration/chessboards/9.jpg', 'calibration/chessboards/10.jpg', 'calibration/chessboards/11.jpg', 'calibration/chessboards/12.jpg']\n"
     ]
    }
   ],
   "source": [
    "dirname = \"calibration/chessboards/\"\n",
    "img_names = [dirname + str(i) + \".jpg\" for i in range(13)]\n",
    "print(img_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During calibration process we need 2D-3D correspondeces. Let us create the 3D coordinate for each corner of the chessboard. \n",
    "\n",
    "We know that 3D coordinates of a corner $c_{i,j}$ will be *i x square_size* and *j x square_size*. \n",
    "\n",
    "The total number of corner is *rows x columns* of the pattern size.\n",
    "\n",
    "We need to produce the 3D coordinate for each corner. For this operation is really useful *np.indices(shape)* which returns an array containing a rows x column array containing the 2D indices of that array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of indices:  (2, 9, 6)\n",
      "[[[0. 0. 0. 0. 0. 0.]\n",
      "  [1. 1. 1. 1. 1. 1.]\n",
      "  [2. 2. 2. 2. 2. 2.]\n",
      "  [3. 3. 3. 3. 3. 3.]\n",
      "  [4. 4. 4. 4. 4. 4.]\n",
      "  [5. 5. 5. 5. 5. 5.]\n",
      "  [6. 6. 6. 6. 6. 6.]\n",
      "  [7. 7. 7. 7. 7. 7.]\n",
      "  [8. 8. 8. 8. 8. 8.]]\n",
      "\n",
      " [[0. 1. 2. 3. 4. 5.]\n",
      "  [0. 1. 2. 3. 4. 5.]\n",
      "  [0. 1. 2. 3. 4. 5.]\n",
      "  [0. 1. 2. 3. 4. 5.]\n",
      "  [0. 1. 2. 3. 4. 5.]\n",
      "  [0. 1. 2. 3. 4. 5.]\n",
      "  [0. 1. 2. 3. 4. 5.]\n",
      "  [0. 1. 2. 3. 4. 5.]\n",
      "  [0. 1. 2. 3. 4. 5.]]]\n"
     ]
    }
   ],
   "source": [
    "indices = np.indices(pattern_size, dtype=np.float32)\n",
    "print(\"Shape of indices: \" , indices.shape)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indices contains nothing less than the coordinate of the pattern!\n",
    "\n",
    "**N.B** we need it in **float** type because later we will need to multiply it with float numbers.\n",
    "\n",
    "Let us see for instance the x and y indices of the position 1,1 in the grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(indices[:,1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1,1) of course!\n",
    "\n",
    "Now we know that each the distance between the corners is exactly 26.5mm (square_size). So we have to multiply this indices by square_size to get the real 3D x,y coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0.    0.    0.    0.    0.    0. ]\n",
      "  [ 26.5  26.5  26.5  26.5  26.5  26.5]\n",
      "  [ 53.   53.   53.   53.   53.   53. ]\n",
      "  [ 79.5  79.5  79.5  79.5  79.5  79.5]\n",
      "  [106.  106.  106.  106.  106.  106. ]\n",
      "  [132.5 132.5 132.5 132.5 132.5 132.5]\n",
      "  [159.  159.  159.  159.  159.  159. ]\n",
      "  [185.5 185.5 185.5 185.5 185.5 185.5]\n",
      "  [212.  212.  212.  212.  212.  212. ]]\n",
      "\n",
      " [[  0.   26.5  53.   79.5 106.  132.5]\n",
      "  [  0.   26.5  53.   79.5 106.  132.5]\n",
      "  [  0.   26.5  53.   79.5 106.  132.5]\n",
      "  [  0.   26.5  53.   79.5 106.  132.5]\n",
      "  [  0.   26.5  53.   79.5 106.  132.5]\n",
      "  [  0.   26.5  53.   79.5 106.  132.5]\n",
      "  [  0.   26.5  53.   79.5 106.  132.5]\n",
      "  [  0.   26.5  53.   79.5 106.  132.5]\n",
      "  [  0.   26.5  53.   79.5 106.  132.5]]]\n"
     ]
    }
   ],
   "source": [
    "indices *= square_size\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got the x,y coordinates of each corner in the world reference system ! (assumed that the first is in position (0mm,0mm)). For instance let us try to plot again the 1,1 corner position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26.5 26.5]\n"
     ]
    }
   ],
   "source": [
    "print(indices[:,1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is in position 26.5,26.5 mm in the world! Moreover, during the camera calibration we assume that all the pixels belonging to the chessboard lie in the same plane with z=0! \n",
    "\n",
    "So the 3D coordinate in the WRS of each corner is just x,y,0!\n",
    "\n",
    "Let us create an array for containing each 3D cordinate. It will have shape *rows x columns x 3*  where rows and columns are refered to the pattern size while 3 is because we need x,y,z values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 3)\n"
     ]
    }
   ],
   "source": [
    "pattern_points = np.zeros((np.prod(pattern_size), 3), np.float32)\n",
    "print(pattern_points.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us assing each x,y to the corresponding corner. We need to transpose the (2,9,6) to become a (6,9,2) array and then reshape it to (54,3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transpose shape:  (6, 9, 2)\n",
      "(54, 2)\n"
     ]
    }
   ],
   "source": [
    "coords_3D = indices.T\n",
    "print(\"Transpose shape: \" , coords_3D.shape)\n",
    "coords_3D = coords_3D.reshape(-1, 2)\n",
    "print(coords_3D.shape)\n",
    "pattern_points[:, :2] = coords_3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the 3D coordinate of each corner in the world reference system we need to get the cooresponding 2D coordinate of each corner in the chessboard images. \n",
    "\n",
    "Let us first load a sample image to understand how to detect corners. It need to be loaded **GRAYSCALE**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"calibration/chessboards/0.jpg\",cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use **cv2.findChessboardCorners(img, pattern_size)** to detect corner in an image. The functions will return a boolean value **found** and the list of the **corners** 2D coordinate in the image. **found** will be true if and only if all the 9x6 corners will be detected in the image. If the image is too dark or too bright the algorithm may fail to detect corners and **found** would be false. \n",
    "\n",
    "**N.B** If you pass the wrong pattern_size the algorithm will look for corners that are not present in the image and the method will be really slow with a **found=False** result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found:  True\n",
      "2D image coordinate of corners:  [[[2774.       697.     ]]\n",
      "\n",
      " [[2752.3247   902.5533 ]]\n",
      "\n",
      " [[2732.7363  1102.0706 ]]\n",
      "\n",
      " [[2709.1055  1295.9447 ]]\n",
      "\n",
      " [[2689.049   1479.8164 ]]\n",
      "\n",
      " [[2673.347   1661.2803 ]]\n",
      "\n",
      " [[2654.8494  1841.0714 ]]\n",
      "\n",
      " [[2638.777   2010.5115 ]]\n",
      "\n",
      " [[2621.      2180.5    ]]\n",
      "\n",
      " [[2591.4824   684.34155]]\n",
      "\n",
      " [[2570.       895.     ]]\n",
      "\n",
      " [[2548.9783  1100.2012 ]]\n",
      "\n",
      " [[2532.4688  1296.8704 ]]\n",
      "\n",
      " [[2514.9172  1482.3511 ]]\n",
      "\n",
      " [[2497.5     1667.     ]]\n",
      "\n",
      " [[2482.2644  1847.2081 ]]\n",
      "\n",
      " [[2468.916   2023.2083 ]]\n",
      "\n",
      " [[2454.9106  2191.0999 ]]\n",
      "\n",
      " [[2398.5      675.5    ]]\n",
      "\n",
      " [[2380.5      890.     ]]\n",
      "\n",
      " [[2362.0938  1094.2607 ]]\n",
      "\n",
      " [[2347.9604  1294.852  ]]\n",
      "\n",
      " [[2332.5     1487.     ]]\n",
      "\n",
      " [[2317.7656  1674.1627 ]]\n",
      "\n",
      " [[2304.832   1852.8756 ]]\n",
      "\n",
      " [[2292.0693  2033.8956 ]]\n",
      "\n",
      " [[2280.4412  2204.0005 ]]\n",
      "\n",
      " [[2197.4026   667.12256]]\n",
      "\n",
      " [[2184.5      883.5    ]]\n",
      "\n",
      " [[2171.      1093.     ]]\n",
      "\n",
      " [[2158.5     1295.     ]]\n",
      "\n",
      " [[2144.8948  1491.245  ]]\n",
      "\n",
      " [[2134.0474  1676.0415 ]]\n",
      "\n",
      " [[2122.8203  1864.1527 ]]\n",
      "\n",
      " [[2112.8494  2041.8182 ]]\n",
      "\n",
      " [[2100.6277  2220.284  ]]\n",
      "\n",
      " [[1991.8837   652.15027]]\n",
      "\n",
      " [[1983.       876.     ]]\n",
      "\n",
      " [[1974.6912  1090.9651 ]]\n",
      "\n",
      " [[1962.4056  1296.5948 ]]\n",
      "\n",
      " [[1955.      1492.     ]]\n",
      "\n",
      " [[1944.5686  1685.6562 ]]\n",
      "\n",
      " [[1937.      1872.     ]]\n",
      "\n",
      " [[1930.7856  2052.6267 ]]\n",
      "\n",
      " [[1920.1735  2231.101  ]]\n",
      "\n",
      " [[1781.7831   639.9713 ]]\n",
      "\n",
      " [[1775.4213   869.77484]]\n",
      "\n",
      " [[1770.2255  1082.8099 ]]\n",
      "\n",
      " [[1760.7009  1293.0698 ]]\n",
      "\n",
      " [[1758.3627  1493.0929 ]]\n",
      "\n",
      " [[1748.8806  1689.328  ]]\n",
      "\n",
      " [[1744.5     1880.5    ]]\n",
      "\n",
      " [[1736.4817  2065.334  ]]\n",
      "\n",
      " [[1730.0114  2249.8674 ]]]\n"
     ]
    }
   ],
   "source": [
    "found, corners = cv2.findChessboardCorners(img, pattern_size)\n",
    "print(\"Found: \" , found)\n",
    "print(\"2D image coordinate of corners: \", corners)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if we **found** th corners, they may be not accurate. To refine the results we can call **cv2.cornerSubPix**. See in OpenCV for more detail about this function. *documentation*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "if found:\n",
    "    #Refining corner position to subpixel iteratively until criteria max_count=30 or criteria_eps_error=1 is sutisfied\n",
    "    term = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_COUNT, 30, 1)\n",
    "    #Image Corners \n",
    "    cv2.cornerSubPix(img, corners, (5, 5), (-1, -1), term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us visualize the founded corners. Follow from red to blu lines to go from (0,0) to (9,6) corner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "cv2.drawChessboardCorners(vis, pattern_size, corners, found)\n",
    "plt.imshow(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we calibrate a camera we need to repeat this operation on all calibration images so I will define a function to process images which return the pairs of (2D,3D) points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processImage(fn):\n",
    "    print('processing {}'.format(fn))\n",
    "    img = cv2.imread(fn, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if img is None:\n",
    "        print(\"Failed to load\", fn)\n",
    "        return None\n",
    "\n",
    "    found, corners = cv2.findChessboardCorners(img, pattern_size)\n",
    "\n",
    "    if found:\n",
    "        #Refining corner position to subpixel iteratively until criteria  max_count=30 or criteria_eps_error=1 is sutisfied\n",
    "        term = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_COUNT, 5, 1)\n",
    "        #Image Corners \n",
    "        cv2.cornerSubPix(img, corners, (5, 5), (-1, -1), term)\n",
    "\n",
    "    vis = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    cv2.drawChessboardCorners(vis, pattern_size, corners, found)\n",
    "    \n",
    "    image_name = fn.split(\"/\")[-1]\n",
    "    basename, ext = image_name.split(\".\")\n",
    "    outfile = os.path.join(\"calibration/output/\", basename + '_chess.png')\n",
    "    cv2.imwrite(outfile, vis)\n",
    "\n",
    "    if not found:\n",
    "        print('chessboard not found')\n",
    "        return None\n",
    "\n",
    "    print('           %s... OK' % fn)\n",
    "    return (corners.reshape(-1, 2), pattern_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing calibration/chessboards/0.jpg\n",
      "           calibration/chessboards/0.jpg... OK\n",
      "processing calibration/chessboards/1.jpg\n",
      "           calibration/chessboards/1.jpg... OK\n",
      "processing calibration/chessboards/2.jpg\n",
      "           calibration/chessboards/2.jpg... OK\n",
      "processing calibration/chessboards/3.jpg\n",
      "           calibration/chessboards/3.jpg... OK\n",
      "processing calibration/chessboards/4.jpg\n",
      "           calibration/chessboards/4.jpg... OK\n",
      "processing calibration/chessboards/5.jpg\n"
     ]
    }
   ],
   "source": [
    "chessboards = [processImage(fn) for fn in img_names]\n",
    "chessboards = [x for x in chessboards if x is not None]\n",
    "\n",
    "obj_points = []\n",
    "img_points = []\n",
    "for (corners, pattern_points) in chessboards:\n",
    "        img_points.append(corners)\n",
    "        obj_points.append(pattern_points)\n",
    "\n",
    "h, w = cv2.imread(img_names[0], cv2.IMREAD_GRAYSCALE).shape[:2]\n",
    "rms, camera_matrix, dist_coefs, rvecs, tvecs = cv2.calibrateCamera(obj_points, img_points, (w, h), None, None)\n",
    "\n",
    "print(\"\\nRMS:\", rms)\n",
    "print(\"camera matrix:\\n\", camera_matrix)\n",
    "print(\"distortion coefficients: \", dist_coefs.ravel())\n",
    "print(\"Rotation vectors:\", rvecs)\n",
    "print(\"translation vectors\", tvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
